name: Data CD - Parse and Upload to Firestore

on:
  pull_request:
    paths:
      - 'data/sources/**'
      - 'data/pipelines/**'
      - 'data/catalogs/scripts/**'
      - '.github/workflows/data-cd.yml'
  push:
    branches: [ main ]
    paths:
      - 'data/sources/**'
      - 'data/pipelines/**'
      - 'data/catalogs/scripts/**'
  workflow_dispatch:
    inputs:
      upload_to_firestore:
        description: 'Upload parsed data to Firestore (only on main branch)'
        required: false
        type: boolean
        default: false

permissions:
  contents: read
  pull-requests: write

jobs:
  parse-data:
    name: Parse Data Sources
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10.14.0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'

      - name: Install poppler-utils (for PDF parsing)
        run: |
          sudo apt-get update
          sudo apt-get install -y poppler-utils

      - name: Install DVC
        run: |
          pip install dvc[gdrive]

      - name: Configure DVC  
        run: |
          echo "â„¹ï¸ DVC configured to use existing remote settings"
          dvc remote list

      - name: Pull source data from DVC
        run: |
          if [ "$GITHUB_ACTIONS" = "true" ]; then
            echo "â„¹ï¸ Skipping DVC pulls in CI - using existing local data"
          else
            dvc pull data/sources/catalogs/ || echo "âš ï¸ DVC pull failed - continuing with existing data"
          fi

      - name: Install dependencies
        working-directory: data
        run: pnpm install --frozen-lockfile

      - name: Parse Catalogs
        id: parse-catalogs
        working-directory: data
        run: |
          echo "ðŸ”„ Parsing catalog PDFs..."
          pnpm run parse:catalog || echo "PARSE_FAILED=true" >> $GITHUB_OUTPUT

          # Generate parsing report
          echo "ðŸ“Š Generating health report..."
          pnpm run health:catalog || true

          # Check if any new files were parsed
          if git diff --name-only | grep -q "data/sources/catalogs/"; then
            echo "NEW_DATA=true" >> $GITHUB_OUTPUT
          fi

      - name: Validate Parsed Data
        if: steps.parse-catalogs.outputs.PARSE_FAILED != 'true'
        working-directory: data
        run: |
          echo "âœ… Validating parsed data..."
          pnpm run validate:catalog

      - name: Generate Parse Report
        if: github.event_name == 'pull_request'
        working-directory: data
        run: |
          # Create a summary of what was parsed
          echo "## ðŸ“Š Parsing Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          # Count new/modified files
          NEW_COUNT=$(git diff --name-only | grep "data/sources/catalogs/" | wc -l || echo "0")
          echo "- **New/Modified Files**: $NEW_COUNT" >> $GITHUB_STEP_SUMMARY
          
          # Show latest parsing report if exists
          if [ -f "analytics/reports/catalog-*.json" ]; then
            LATEST_REPORT=$(ls -t analytics/reports/catalog-*.json | head -1)
            echo "- **Latest Report**: \`$LATEST_REPORT\`" >> $GITHUB_STEP_SUMMARY
            
            # Extract key metrics from report
            if command -v jq >/dev/null 2>&1; then
              TOTAL_COURSES=$(jq -r '.summary.totalCourses // 0' "$LATEST_REPORT")
              PARSE_ERRORS=$(jq -r '.summary.parseErrors // 0' "$LATEST_REPORT")
              echo "- **Total Courses**: $TOTAL_COURSES" >> $GITHUB_STEP_SUMMARY
              echo "- **Parse Errors**: $PARSE_ERRORS" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      - name: Comment on PR with Results
        if: github.event_name == 'pull_request' && steps.parse-catalogs.outputs.NEW_DATA == 'true'
        uses: actions/github-script@v8
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // Read the step summary
            const summary = fs.readFileSync(process.env.GITHUB_STEP_SUMMARY, 'utf8');
            
            // Create PR comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ðŸ¤– Data Parsing Results\n\n${summary}\n\nâœ… All validations passed. These changes will be uploaded to Firestore when merged.`
            });

      - name: Upload parsed data artifacts
        if: steps.parse-catalogs.outputs.NEW_DATA == 'true'
        uses: actions/upload-artifact@v5
        with:
          name: parsed-data
          path: |
            data/sources/catalogs/
            data/analytics/reports/
          retention-days: 7

  upload-to-firestore:
    name: Upload to Firestore
    needs: parse-data
    runs-on: ubuntu-latest
    # Only run on main branch or manual trigger
    if: |
      (github.ref == 'refs/heads/main' && github.event_name == 'push') ||
      (github.event_name == 'workflow_dispatch' && github.event.inputs.upload_to_firestore == 'true')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10.14.0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'

      - name: Install dependencies
        working-directory: data
        run: pnpm install --frozen-lockfile

      - name: Download parsed data
        uses: actions/download-artifact@v6
        with:
          name: parsed-data
          path: data/

      - name: Set up Firebase credentials
        env:
          FIREBASE_SERVICE_ACCOUNT: ${{ secrets.FIREBASE_SERVICE_ACCOUNT }}
        run: |
          echo "$FIREBASE_SERVICE_ACCOUNT" > serviceAccount.json

      - name: Upload Catalog Data to Firestore
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/serviceAccount.json
        working-directory: data
        run: |
          echo "ðŸ“¤ Uploading catalog data to Firestore..."
          pnpm run upload:academic-registry

          echo "âœ… Data successfully uploaded to Firestore!"

      - name: Verify Upload
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ github.workspace }}/serviceAccount.json
        working-directory: data
        run: |
          echo "ðŸ” Verifying Firestore data..."
          pnpm run verify:firestore || echo "Verification script not found, skipping..."

      - name: Clean up credentials
        if: always()
        run: rm -f serviceAccount.json

      - name: Create success notification
        run: |
          echo "## âœ… Firestore Upload Complete" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Timestamp**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> $GITHUB_STEP_SUMMARY